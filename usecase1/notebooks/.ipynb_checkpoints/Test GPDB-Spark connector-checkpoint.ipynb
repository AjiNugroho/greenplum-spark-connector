{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%AddJar file:///home/jovyan/work/data/postgresql-42.2.2.jar -f\n",
    "%AddJar file:///home/jovyan/work/data/greenplum-spark_2.11-1.4.0-alpha.jar -f\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "|num|letter|\n",
      "+---+------+\n",
      "|  1|     a|\n",
      "|  5|     z|\n",
      "+---+------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "data = List([1,a], [5,z])\n",
       "schema = StructType(StructField(num,IntegerType,true), StructField(letter,StringType,true))\n",
       "df = [num: int, letter: string]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[num: int, letter: string]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.Row\n",
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.types.DataType._\n",
    "import org.apache.spark.sql.types.{StructField, StructType}\n",
    "import org.apache.spark.sql.types._\n",
    "\n",
    "val data = Seq(\n",
    "  Row(1, \"a\"),\n",
    "  Row(5, \"z\")\n",
    ")\n",
    "\n",
    "val schema = StructType(\n",
    "  List(\n",
    "    StructField(\"num\", IntegerType, true),\n",
    "    StructField(\"letter\", StringType, true)\n",
    "  )\n",
    ")\n",
    "\n",
    "val df = spark.createDataFrame(\n",
    "  spark.sparkContext.parallelize(data),\n",
    "  schema\n",
    ")\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Class.forName(\"org.postgresql.Driver\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: java.lang.NoSuchMethodError\n",
       "Message: org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.getSchema(Ljava/sql/ResultSet;Lorg/apache/spark/sql/jdbc/JdbcDialect;)Lorg/apache/spark/sql/types/StructType;\n",
       "StackTrace:   at io.pivotal.greenplum.spark.jdbc.Jdbc$.resolveTable(Jdbc.scala:298)\n",
       "  at io.pivotal.greenplum.spark.GreenplumRelationProvider.createRelation(GreenplumRelationProvider.scala:46)\n",
       "  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:340)\n",
       "  at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:239)\n",
       "  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:227)\n",
       "  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:164)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dataFrame = spark.read.format(\"io.pivotal.greenplum.spark.GreenplumRelationProvider\")\n",
    ".option(\"dbtable\", \"usertable\")\n",
    ".option(\"url\", \"jdbc:postgresql://gpdbsne/basic_db\")\n",
    ".option(\"user\", \"gpadmin\")\n",
    ".option(\"password\", \"pivotal\")\n",
    ".option(\"partitionColumn\", \"id\")\n",
    ".load()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val opts = Map(\"url\" -> \"jdbc:postgresql://gpdbsne/basic_db?user=gpadmin&password=pivotal\",\"dbtable\" -> \"usertable\")\n",
    "val df = spark.read.format(\"jdbc\").options(opts).load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lastException = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Name: java.lang.InstantiationException\n",
       "Message: org.apache.spark.sql.execution.datasources.jdbc.DriverWrapper\n",
       "StackTrace:   at org.apache.spark.sql.execution.datasources.jdbc.DriverRegistry$.register(DriverRegistry.scala:53)\n",
       "  at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$$anonfun$createConnectionFactory$1.apply(JdbcUtils.scala:55)\n",
       "  at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$$anonfun$createConnectionFactory$1.apply(JdbcUtils.scala:54)\n",
       "  at org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD$.resolveTable(JDBCRDD.scala:56)\n",
       "  at org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation.<init>(JDBCRelation.scala:115)\n",
       "  at org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:52)\n",
       "  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:340)\n",
       "  at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:239)\n",
       "  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:227)\n",
       "  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:164)\n",
       "  ... 50 elided\n",
       "Caused by: java.lang.NoSuchMethodException: org.apache.spark.sql.execution.datasources.jdbc.DriverWrapper.<init>()\n",
       "  at java.lang.Class.getConstructor0(Class.java:3082)\n",
       "  at java.lang.Class.newInstance(Class.java:412)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "val jdbcDF = spark.read\n",
    "  .format(\"jdbc\")\n",
    "  .option(\"url\", \"jdbc:postgresql://gpdbsne:5432/basic_db\")\n",
    "  .option(\"dbtable\", \"usertable\")\n",
    "  .option(\"user\", \"gpadmin\")\n",
    "  .option(\"password\", \"pivotal\")\n",
    "  .option(\"partitionColumn\", \"id\")\n",
    "  .option(\"lowerBound\", \"0\")\n",
    "  .option(\"upperBound\", \"1000\")\n",
    "  .option(\"numPartitions\", \"100\")\n",
    "  .load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
